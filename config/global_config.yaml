# Managed by Hydra

hydra:
  output_subdir: null
  run:
    dir: .

defaults:
  - _self_
  - data: re10k
  - view_sampler: bounded
  - model: encoder_decoder
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

project_root_path: ${hydra:runtime.cwd}
experiment_output_path: ${project_root_path}/output/${experiment_name}

inference_dir: null
ckpt_path: null
experiment_name: null
train_seed: 123
test_seed: 123
debug: false

logger:
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html
  _target_: lightning.pytorch.loggers.WandbLogger
  project: Accelerate-sampling
  # project: debug
  name: ${experiment_name}
  save_dir: ${experiment_output_path}/training

# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
trainer:
  accelerator: gpu
  max_epochs: 200
  num_sanity_val_steps: 1
  check_val_every_n_epoch: 5
  profiler: simple
  precision: 32
  log_every_n_steps: 20

# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html
checkpoint_monitor:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  monitor: val_loss/total_loss
  mode: min
  save_last: False
  save_top_k: 3
  every_n_epochs: ${trainer.check_val_every_n_epoch}
  filename: "{epoch}"
  dirpath: ${experiment_output_path}/training

last_checkpoint:
  _target_: lightning.pytorch.callbacks.ModelCheckpoint
  save_top_k: 1
  every_n_epochs: 1
  save_on_train_epoch_end: True
  filename: "last"
  dirpath: ${experiment_output_path}/training


base_model:
  _target_: src.lightning_lift.LightningLiFTWrapper

loss:
  perceptual_weight: 0.5

save_images: false
save_videos: false
